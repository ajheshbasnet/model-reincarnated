{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NKjYQjxg7qQK"
      },
      "outputs": [],
      "source": [
        "import wandb\n",
        "import torch\n",
        "import os\n",
        "import torch.nn as nn\n",
        "from datasets import load_dataset\n",
        "from transformers import GPT2Tokenizer, GPT2LMHeadModel, GPT2Model\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from dataclasses import dataclass\n",
        "from tqdm import tqdm\n",
        "from datasets import load_dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# training takes a lot of time so better so save the weights of optimizers and model"
      ],
      "metadata": {
        "id": "I8NZc8H8vul_"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "XI8zAfoVFAWC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def getwandbrun(cfgs):\n",
        "  wandb.login(key=cfgs.WANDBAPI_KEY)\n",
        "  run = wandb.init(\n",
        "      entity=\"ajheshbasnet-kpriet\",\n",
        "      project=\"RLVR\",\n",
        "      name = \"grpo-training-loop\",\n",
        "      config=vars(cfgs),\n",
        "  )\n",
        "  return run"
      ],
      "metadata": {
        "id": "8l8zqg6f7ys_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "@dataclass\n",
        "class configs:\n",
        "  MAX_SEQ_LEN = 512\n",
        "  SFT_LEARNING_RATE = 2.5e-5\n",
        "  SFT_EPOCHS = 6\n",
        "  EVAL_EVERY_STEP = 12\n",
        "  GRADIENT_ACCUM_STEPS = 32 # Increased to compensate for smaller batch size\n",
        "  MODEL_NAME = \"gpt2\"\n",
        "  WANDBAPI_KEY = \"\"\n",
        "  SFT_TRAIN_BATCH_SIZE = 8 # Reduced to save VRAM\n",
        "  SFT_VALID_BATCH_SIZE = 4\n",
        "  DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "cfg = configs()"
      ],
      "metadata": {
        "id": "IIDDwxp8hyam"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = GPT2LMHeadModel.from_pretrained(cfg.MODEL_NAME).to(cfg.DEVICE)"
      ],
      "metadata": {
        "id": "g-QMO8xcAYnI",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "I used the Pad token as EOS token but it is handled well using masking in the loop"
      ],
      "metadata": {
        "id": "x8Yr3LHSvk2k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = GPT2Tokenizer.from_pretrained(cfg.MODEL_NAME)\n",
        "tokenizer.padding_side = \"left\"\n",
        "# tokenizer.add_special_tokens({'pad_token': '<PAD>'})\n",
        "# model.resize_token_embeddings(len(tokenizer))"
      ],
      "metadata": {
        "id": "k4coeuS77FQs",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.pad_token_id = tokenizer.eos_token_id"
      ],
      "metadata": {
        "id": "vcBqzRVvaHp_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "runs = getwandbrun(cfg)"
      ],
      "metadata": {
        "id": "uCzqDX0N_CAy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# checkpoint = {\n",
        "# 'epoch': epoch,\n",
        "# 'model_state_dict': model.state_dict(),\n",
        "# 'optimizer_state_dict': SFT_OPTIMIZER.state_dict(),\n",
        "# 'loss': loss,\n",
        "# }"
      ],
      "metadata": {
        "id": "2YtKrLv81wW1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# save_dir = \"/content/drive/MyDrive/sft-optimizer\"\n",
        "# os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "# filename = f\"checkpoint_epoch_{epoch}.pth\"\n",
        "# torch.save(checkpoint, os.path.join(save_dir, filename))"
      ],
      "metadata": {
        "id": "cSfhCzhQ2LqB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **REWARD MODEL**"
      ],
      "metadata": {
        "id": "aYBLN2QljGau"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rl_dataset = load_dataset(\"CarperAI/openai_summarize_comparisons\")"
      ],
      "metadata": {
        "id": "s2gexqfE1A_I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rl_dataset_train = rl_dataset['train'].select(torch.randperm(len(rl_dataset['train']))[:500])\n",
        "rl_dataset_valid = rl_dataset['valid1'].select(torch.randperm(len(rl_dataset['valid1']))[:50])\n",
        "\n",
        "rl_dataset_train, rl_dataset_valid"
      ],
      "metadata": {
        "id": "A7bXCfL_jM1U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class RewardModel(nn.Module):\n",
        "\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "    self.base_model = GPT2Model.from_pretrained(cfg.MODEL_NAME)\n",
        "    self.reward_head = nn.Sequential(\n",
        "        nn.Linear(768, 1)\n",
        "        )\n",
        "\n",
        "  def forward(self, x, attn_mask, eos_idx=None):\n",
        "    h_s = self.base_model(input_ids = x, attention_mask=attn_mask).last_hidden_state\n",
        "    if eos_idx == None:\n",
        "      chosen_idx = (torch.fill(torch.zeros(h_s.size(0),), h_s.size(1)) - 1).long()\n",
        "    else:\n",
        "      chosen_idx = eos_idx\n",
        "    hs = h_s[torch.arange(h_s.size(0), dtype=torch.long, device = h_s.device), chosen_idx]\n",
        "    rewards = self.reward_head(hs)\n",
        "    return rewards"
      ],
      "metadata": {
        "id": "PKDX7gWrrt7W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reward_model = RewardModel().to(cfg.DEVICE)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "D7u_9hQd1sFS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sft_checkpointer=torch.load(\"/content/drive/MyDrive/sft-optimizer/checkpoint_epoch_4.pth\")"
      ],
      "metadata": {
        "id": "SYyS1rKTrgLa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(sft_checkpointer['model_state_dict'])"
      ],
      "metadata": {
        "id": "VoR6ATEat4mf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rew_checkpointer=torch.load(\"/content/drive/MyDrive/checkpoints/rewards_weights\")"
      ],
      "metadata": {
        "id": "DjJU5zJtbNRy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint = torch.load(\"/content/drive/MyDrive/checkpoints/rewards_weights\")\n",
        "\n",
        "new_state_dict = {}\n",
        "for k, v in checkpoint.items():\n",
        "    new_key = k.replace(\"_orig_mod.\", \"\")\n",
        "    new_state_dict[new_key] = v\n",
        "\n",
        "reward_model.load_state_dict(new_state_dict)"
      ],
      "metadata": {
        "id": "7RofuG8ZwSdH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GRPO**"
      ],
      "metadata": {
        "id": "sOEPDUjFz7a0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DEVICE = \"cuda\"\n",
        "LR = 2e-5\n",
        "KL_COEF = 0.01\n",
        "PPO_EPS = 0.2\n",
        "GRAD_ACCUM = 2\n",
        "MAX_NEW_TOKENS = 54\n",
        "NUM_SAMPLES = 4\n",
        "TEMPERATURE = 0.6\n",
        "EVAL_INTERVAL = 6000\n",
        "TRAIN_BATCH_SIZE = 1\n",
        "VALID_BATCH_SIZE = 2\n",
        "MAX_PROMPT_LENGTH = 500\n",
        "DRIVE_CHECKPOINTER = 10_000\n",
        "UPDATE_WEIGHTS = 500\n",
        "MAX_N_STEPS = 10"
      ],
      "metadata": {
        "id": "oNH28CXugdER"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GRPODataset(Dataset):\n",
        "\n",
        "  def __init__(self, ds):\n",
        "\n",
        "    self.prompt = ds\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.prompt)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    tokenized = tokenizer(self.prompt[index], max_length = MAX_PROMPT_LENGTH,  truncation=True, padding = \"max_length\", return_tensors=\"pt\")\n",
        "    ids = tokenized['input_ids'][0]\n",
        "    msk = tokenized['attention_mask'][0]\n",
        "    return ids, msk"
      ],
      "metadata": {
        "id": "ZCTEEMZPl4FJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grpo_trainds = GRPODataset(rl_dataset_train['prompt'])\n",
        "grpo_validds = GRPODataset(rl_dataset_valid['prompt'])"
      ],
      "metadata": {
        "id": "oYHF54fZ1nMR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataloader = DataLoader(grpo_trainds, batch_size = TRAIN_BATCH_SIZE, shuffle = True)\n",
        "valid_dataloader = DataLoader(grpo_trainds, batch_size = VALID_BATCH_SIZE, shuffle = True)"
      ],
      "metadata": {
        "id": "KDbjc4B9Y4o8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import copy\n",
        "\n",
        "frozen_model = copy.deepcopy(model)\n",
        "\n",
        "for p in frozen_model.parameters():\n",
        "    p.requires_grad = False\n",
        "\n",
        "_ = frozen_model.eval()"
      ],
      "metadata": {
        "id": "u1wGgFLJ4wIr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.AdamW(model.parameters(), lr=LR)"
      ],
      "metadata": {
        "id": "DSp0q_AVb2sc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "FPKnvs7ZhGW_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for _ in range(MAX_N_STEPS):\n",
        "\n",
        "    buffer = {\n",
        "        \"outputs\": [],\n",
        "        \"attn_mask\": [],\n",
        "        \"prompt_mask\": [],\n",
        "        \"advantages\": [],\n",
        "        \"old_log_probs\": [],\n",
        "        \"loss_mask\":[]\n",
        "    }\n",
        "\n",
        "    for step, batch in tqdm(enumerate(train_dataloader)):\n",
        "\n",
        "        ids, msk = batch\n",
        "        ids, msk = ids.to(cfg.DEVICE), msk.to(cfg.DEVICE)\n",
        "\n",
        "        outputs = model.generate(\n",
        "                        ids,\n",
        "                        attention_mask=msk,\n",
        "                        do_sample=True,\n",
        "                        temperature=TEMPERATURE,\n",
        "                        max_new_tokens=MAX_NEW_TOKENS,\n",
        "                        num_return_sequences=NUM_SAMPLES,\n",
        "                        pad_token_id=tokenizer.pad_token_id\n",
        "                    )\n",
        "\n",
        "        prompt_len = ids.size(-1)\n",
        "\n",
        "        response = outputs[:, prompt_len:]\n",
        "\n",
        "        response_msk = (torch.cumsum((response == tokenizer.eos_token_id).int(), dim = -1)<=1).long() # only includes first <EOS_TOKEN > response + <EOS>=1 others 0.\n",
        "\n",
        "        # this is for masking prompts and seen only response for the loss calculation - here we mask prompts = PAD = 0 and response+<EPS>=1\n",
        "\n",
        "        prompt_mask = torch.zeros((outputs.size(0), ids.size(-1)), device = ids.device)\n",
        "\n",
        "        loss_mask = torch.cat((prompt_mask, response_msk), dim = -1)\n",
        "\n",
        "        response_eos_length = ids.size(-1) + response_msk.sum(dim = -1) -1  # -1 for indices.\n",
        "\n",
        "        attn_mask = torch.cat((msk[torch.floor(torch.arange(outputs.size(0)) / NUM_SAMPLES).long()], response_msk), dim = -1)\n",
        "\n",
        "        r = reward_model(outputs, attn_mask, response_eos_length.view(-1)).view(-1, NUM_SAMPLES)\n",
        "\n",
        "        advantages = (r - r.mean(dim = -1, keepdim = True)) / (r.std(dim = -1, keepdim = True) + 1e-8)\n",
        "\n",
        "        logits = F.log_softmax(model(outputs, attention_mask = attn_mask).logits, dim = -1)\n",
        "\n",
        "        input_logits = logits[:, :-1, :]\n",
        "\n",
        "        target_ids = outputs[:, 1:]\n",
        "\n",
        "        new_log_probs = input_logits.gather(dim = -1, index = target_ids.unsqueeze(-1)).squeeze(-1)                # [B*N, T_MAX]\n",
        "\n",
        "        advantages = advantages.view(-1, 1).detach()            #[BXH, 1]\n",
        "\n",
        "        buffer['outputs'].append((outputs.detach().cpu()))\n",
        "        buffer['prompt_mask'].append((prompt_mask.detach().cpu()))\n",
        "        buffer['attn_mask'].append((attn_mask.detach().cpu()))\n",
        "        buffer['old_log_probs'].append((new_log_probs.detach().cpu()))\n",
        "        buffer['advantages'].append((advantages.detach().cpu()))\n",
        "        buffer['loss_mask'].append((loss_mask.detach().cpu()))\n",
        "\n",
        "\n",
        "        runs.log({\"step\":step})\n",
        "        if (step+1) % UPDATE_WEIGHTS == 0:\n",
        "\n",
        "          all_indices = torch.randperm(len(buffer['outputs']))\n",
        "\n",
        "          for idx in range(0, len(buffer['outputs']), TRAIN_BATCH_SIZE):\n",
        "\n",
        "              start_idx = idx\n",
        "              end_idx = start_idx + TRAIN_BATCH_SIZE\n",
        "\n",
        "              batch_indices = all_indices[start_idx:end_idx]\n",
        "\n",
        "              batch_outputs = buffer['outputs'][batch_indices].to(cfg.DEVICE)\n",
        "              batch_attn_mask = buffer['attn_mask'][batch_indices].to(cfg.DEVICE)\n",
        "              batch_old_log_probs = buffer['old_log_probs'][batch_indices].to(cfg.DEVICE)\n",
        "              batch_advantages = buffer['advantages'][batch_indices].to(cfg.DEVICE)\n",
        "              batch_loss_mask = buffer['loss_mask'][batch_indices].to(cfg.DEVICE)\n",
        "\n",
        "              batch_new_logits = F.log_softmax(model(batch_outputs, attention_mask = batch_attn_mask).logits, dim = -1)\n",
        "\n",
        "              batch_target = batch_outputs[:, 1:]\n",
        "              batch_input = batch_new_logits[:, :-1, :]\n",
        "\n",
        "              batch_new_log_probs = batch_input.gather(dim = -1, index = batch_target.unsqueeze(-1)).squeeze(-1)\n",
        "\n",
        "              ratio = torch.exp(batch_new_log_probs - batch_old_log_probs)        #[BXH, T]\n",
        "\n",
        "              policy_loss = - (torch.min(ratio*batch_advantages, torch.clamp(ratio, 1 - PPO_EPS, 1 + PPO_EPS)*batch_advantages) * batch_attn_mask[:, 1:]).sum()/ batch_attn_mask[:, 1:].sum()\n",
        "\n",
        "\n",
        "              # ==================== KL-DIVERGENCE ==================== #\n",
        "\n",
        "              ref_log_logits = F.log_softmax(frozen_model(batch_outputs, attention_mask=batch_attn_mask).logits, dim = -1)\n",
        "\n",
        "              ref_log_probs = ref_log_logits[:, :-1, :].gather(dim = -1, index = batch_target.unsqueeze(-1)).squeeze(-1)\n",
        "\n",
        "              kl_div_per_token = (batch_new_log_probs - ref_log_probs)     # [BXH , T]\n",
        "              kl_div = (kl_div_per_token * batch_loss_mask[:, 1:]).sum() / batch_loss_mask[:, 1:].sum()\n",
        "\n",
        "              loss_GRPO = policy_loss + KL_COEF * kl_div\n",
        "\n",
        "              optimizer.zero_grad()\n",
        "              loss_GRPO.backward()\n",
        "              optimizer.step()\n",
        "\n",
        "              runs.log({\"loss-grpo\": loss_GRPO.item(), \"kl-div\": kl_div.item(), \"policy-loss\": policy_loss.item()})\n",
        "\n",
        "          buffer = {\n",
        "                  \"outputs\": [],\n",
        "                  \"attn_mask\": [],\n",
        "                  \"prompt_mask\": [],\n",
        "                  \"advantages\": [],\n",
        "                  \"old_log_probs\": [],\n",
        "                  \"loss_mask\":[]\n",
        "              }"
      ],
      "metadata": {
        "id": "kUEmyAQqXwl0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "  (batch_new_log_probs)# - ref_log_probs)"
      ],
      "metadata": {
        "id": "KEZQv0IGkWJ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "step"
      ],
      "metadata": {
        "id": "HggcUp8JGBkL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outputs[2][544]"
      ],
      "metadata": {
        "id": "gtDcVydJ_iUB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outputs"
      ],
      "metadata": {
        "id": "weiYroZF_qA4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wEKG2Ee7_z-M"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}